# ðŸŒ² Heart Disease Prediction â€“ Decision Tree & Random Forest

This project was completed for **Day 5 of the AI/ML Internship**, where the goal was to build and compare tree-based classification models using the **Heart Disease Dataset**.

---

## ðŸ“Œ Objectives

- âœ… Train a **Decision Tree Classifier**
- âœ… Visualize the full decision tree
- âœ… Prevent overfitting using `max_depth`
- âœ… Train a **Random Forest Classifier**
- âœ… Interpret **feature importances**
- âœ… Evaluate with **cross-validation**

---

## ðŸ“‚ Dataset

- ðŸ“¥ Source: [Kaggle â€“ Heart Disease Dataset](https://www.kaggle.com/datasets/johnsmith88/heart-disease-dataset)
- ðŸŽ¯ Target Column: `target`
  - `0` â†’ No heart disease
  - `1` â†’ Has heart disease

---

## ðŸŒ³ Decision Tree Results

| Version     | Accuracy |
|-------------|----------|
| Full Tree   | 98.54%   |
| Pruned Tree (max_depth=4) | 80.00% |

- ðŸ“‰ Full tree showed signs of overfitting.
- âœ‚ï¸ Pruning reduced overfitting at the cost of accuracy.

---

## ðŸŒ² Random Forest Results

- âœ… Accuracy: **98.54%**
- ðŸ” 5-Fold Cross-Validation Accuracy: **99.71%**
- ðŸ” Feature Importance showed `thal`, `cp`, `ca` as most influential

---

## ðŸ“Š Feature Importance (Random Forest)

Bar chart was generated using `rf.feature_importances_`  
Top features: `thal`, `ca`, `cp`, `oldpeak`, `age`

---

## ðŸ›  Libraries Used

- `pandas`, `numpy`
- `scikit-learn`
- `matplotlib`, `seaborn`

---

## ðŸ“ Files Included

- `Day5_DecisionTree_RandomForest_HeartDisease.ipynb`
- `heart.csv`
- `README.md`
- `screenshots/`


---

## âœ… Internship Submission

> This project was completed as part of **Day 5 â€“ AI & ML Internship Program**
